{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import subprocess\n",
    "import shutil\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_wav(src_path: Path, dst_path: Path):\n",
    "    dst_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    subprocess.check_call([\n",
    "        \"sox\",\n",
    "        \"-t\", \"wav\",\n",
    "        str(src_path),\n",
    "        \"-r\", \"16000\",\n",
    "        \"-e\", \"signed-integer\",\n",
    "        \"-c\", \"1\",\n",
    "        \"-t\", \"wav\",\n",
    "        str(dst_path)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(s: str) -> str:\n",
    "    s = s.strip().lower()\n",
    "    return re.sub(r\"[.,?':]\", \"\", s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LapsBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(\"wav/lapsbm\")\n",
    "for speaker_dir in Path(\"data/lapsbm\").glob(\"*\"):\n",
    "    speaker_id = speaker_dir.name\n",
    "    for wav_file in speaker_dir.glob(\"*.wav\"):\n",
    "        utterance_id = wav_file.stem\n",
    "        file_id = f\"lapsbm/{speaker_id}/{utterance_id}\"\n",
    "        text_file = speaker_dir / f\"{utterance_id}.txt\"\n",
    "        transcriptions[file_id] = clean_string(text_file.read_text())\n",
    "        dst_path = dataset_dir / speaker_id / f\"{utterance_id}.wav\"\n",
    "        if not dst_path.exists():\n",
    "            convert_wav(wav_file, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transcriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(\"wav/sid\")\n",
    "for speaker_dir in Path(\"data/sid\").glob(\"*\"):\n",
    "    speaker_id = speaker_dir.name\n",
    "    with open(speaker_dir / \"prompts.txt\", \"r\") as prompts_file:\n",
    "        for line in prompts_file:\n",
    "            line = line.strip()\n",
    "            prompt_num, prompt = line.split(\"=\", maxsplit=1)\n",
    "            prompt_num = int(prompt_num)\n",
    "            utterance_id = \"{0}{1:03d}\".format(speaker_id, prompt_num)\n",
    "            file_id = f\"sid/{speaker_id}/{utterance_id}\"\n",
    "            src_path = speaker_dir / f\"{utterance_id}.wav\"\n",
    "            if src_path.exists():\n",
    "                transcriptions[file_id] = clean_string(prompt)\n",
    "                dst_path = dataset_dir / speaker_id / f\"{utterance_id}.wav\"\n",
    "                \n",
    "                if not dst_path.exists():\n",
    "                    convert_wav(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5793"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transcriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voxforge pt-br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(\"wav/voxforge-ptbr\")\n",
    "for speaker_dir in Path(\"data/voxforge-ptbr\").glob(\"*\"):\n",
    "    speaker_id = speaker_dir.name\n",
    "    prompts_path = speaker_dir / \"PROMPTS\"\n",
    "    if not prompts_path.exists():\n",
    "        prompts_path = speaker_dir / \"etc\" / \"PROMPTS\"\n",
    "    with open(prompts_path, \"r\") as prompts_file:\n",
    "        for line in prompts_file:\n",
    "            line = line.strip()\n",
    "            prompt_id, prompt = line.split(\" \", maxsplit=1)\n",
    "            prompt_num = prompt_id.split(\"/\")[-1]\n",
    "            file_id = f\"voxforge-ptbr/{speaker_id}/{prompt_num}\"\n",
    "            src_path = speaker_dir / f\"{prompt_num}.wav\"\n",
    "            if not src_path.exists():\n",
    "                src_path = speaker_dir / \"wav\" / f\"{prompt_num}.wav\"\n",
    "            if src_path.exists():\n",
    "                transcriptions[file_id] = clean_string(prompt)\n",
    "                dst_path = dataset_dir / speaker_id / f\"{prompt_num}.wav\"\n",
    "                if not dst_path.exists():\n",
    "                    convert_wav(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9923"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transcriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(\"data/test\")\n",
    "for wav_file in dataset_dir.glob(\"*.wav\"):\n",
    "    utterance_id = wav_file.stem\n",
    "    file_id = f\"test/{utterance_id}\"\n",
    "    text_file = dataset_dir / f\"{utterance_id}.txt\"\n",
    "    transcriptions[file_id] = clean_string(text_file.read_text())\n",
    "    dst_path = Path(\"wav\") / \"test\" / f\"{utterance_id}.wav\"\n",
    "    if not dst_path.exists():\n",
    "        convert_wav(wav_file, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9933"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transcriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sphinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"etc/pt-synesthesiam.fileids\", \"w\") as fileids_file:\n",
    "    for key in sorted(transcriptions):\n",
    "        print(key, file=fileids_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"etc/pt-synesthesiam.transcription\", \"w\") as trans_file:\n",
    "    for key in sorted(transcriptions):\n",
    "        t = transcriptions[key]\n",
    "        print(f\"<s> {t} </s>\", f\"({key})\", file=trans_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_words = set()\n",
    "known_dict = {}\n",
    "with open(\"etc/pt-synesthesiam.dic.full\", \"r\") as dict_file:\n",
    "    for line in dict_file:\n",
    "        line = line.strip()\n",
    "        if (len(line) == 0) or (\"(\" in line):\n",
    "            continue\n",
    "            \n",
    "        word, phonemes = re.split(r\"\\s+\", line, maxsplit=1)\n",
    "        known_words.add(word)\n",
    "        known_dict[word] = phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30710"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(known_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_words = set()\n",
    "for sentence in transcriptions.values():\n",
    "    words = [w for w in re.split(r\"\\s+\", sentence) if len(w) > 0]\n",
    "    trans_words.update(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_words = trans_words - known_words\n",
    "len(unknown_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"etc/unknown_words.txt\", \"w\") as unknown_file:\n",
    "    for word in unknown_words:\n",
    "        print(word, file=unknown_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'etc/pt-synesthesiam.dic'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy(\"etc/pt-synesthesiam.dic.original\", \"etc/pt-synesthesiam.dic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"etc/pt-synesthesiam.dic\", \"a\") as dict_file:\n",
    "    with open(\"etc/guess.json\", \"r\") as guess_file:\n",
    "        guesses = json.load(guess_file)\n",
    "        for word, prons in guesses.items():\n",
    "            print(word, prons[0], file=dict_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"etc/corpus.txt\", \"w\") as corpus_file:\n",
    "    for sentence in transcriptions.values():\n",
    "        print(sentence + \".\", file=corpus_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ngramsymbols etc/corpus.txt etc/corpus.syms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "!farcompilestrings -keep_symbols=1 -symbols=etc/corpus.syms etc/corpus.txt etc/corpus.far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ngramcount -order=3 etc/corpus.far etc/corpus.cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ngrammake etc/corpus.cnts etc/corpus.mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ngramprint --ARPA etc/corpus.mod etc/pt-synesthesiam.lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current configuration:\n",
      "[NAME]\t\t[DEFLT]\t[VALUE]\n",
      "-case\t\t\t\n",
      "-help\t\tno\tno\n",
      "-i\t\t\tetc/pt-synesthesiam.lm\n",
      "-ifmt\t\t\t\n",
      "-logbase\t1.0001\t1.000100e+00\n",
      "-mmap\t\tno\tno\n",
      "-o\t\t\tetc/pt-synesthesiam.lm.DMP\n",
      "-ofmt\t\t\t\n",
      "\n",
      "INFO: ngram_model_trie.c(354): Trying to read LM in trie binary format\n",
      "INFO: ngram_model_trie.c(365): Header doesn't match\n",
      "INFO: ngram_model_trie.c(177): Trying to read LM in arpa format\n",
      "INFO: ngram_model_trie.c(193): LM of order 3\n",
      "INFO: ngram_model_trie.c(195): #1-grams: 7611\n",
      "INFO: ngram_model_trie.c(195): #2-grams: 21052\n",
      "INFO: ngram_model_trie.c(195): #3-grams: 25744\n",
      "INFO: lm_trie.c(474): Training quantizer\n",
      "INFO: lm_trie.c(482): Building LM trie\n"
     ]
    }
   ],
   "source": [
    "!sphinx_lm_convert -i etc/pt-synesthesiam.lm -o etc/pt-synesthesiam.lm.DMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"etc/pt-synesthesiam.dic\", \"w\") as dict_file:\n",
    "    for word in trans_words:\n",
    "        print(word, known_dict[word], file=dict_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"etc/pt-synesthesiam_train.transcription\", \"w\") as train_file:\n",
    "    with open(\"etc/pt-synesthesiam_test.transcription\", \"w\") as test_file:\n",
    "        with open(\"etc/pt-synesthesiam_test.fileids\", \"w\") as test_ids_file:\n",
    "            for key in sorted(transcriptions):\n",
    "                sentence = transcriptions[key]\n",
    "                if key.startswith(\"test/\"):\n",
    "                    print(\"<s>\", sentence, \"</s>\", f\"({key})\", file=test_file)\n",
    "                    print(key, file=test_ids_file)\n",
    "                else:\n",
    "                    print(\"<s>\", sentence, \"</s>\", f\"({key})\", file=train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
